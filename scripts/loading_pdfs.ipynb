{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: Redis Microservices.pdf\n",
      "Uploaded: Analytics Stack Guidebook.pdf\n",
      "Uploaded: Node.js Design Patterns 3rd Edition.pdf\n",
      "Uploaded: Redis For Dummies Limited Edition.pdf\n",
      "Uploaded: Caching at Scale with Redis Dec 2021.pdf\n",
      "Uploaded: Caching for Microservices Brief.pdf\n",
      "Error extracting text from ../content/pdfs/Practical Node.js 2nd Edition.pdf: unpack requires a buffer of 30 bytes\n",
      "Uploaded: Practical Node.js 2nd Edition.pdf\n",
      "Uploaded: Designing Data-Intensive Applications.pdf\n",
      "Uploaded: Hands On JavaScript High Performance.pdf\n",
      "Uploaded: Microservices Building Scalable Software.pdf\n",
      "Uploaded: Node.js High Performance.pdf\n",
      "Uploaded: Mastering Node.js.pdf\n",
      "Uploaded: Object Oriented Design Course Notes.pdf\n",
      "Uploaded: System Design Interview An Insider’s Guide by Alex Xu (z-lib.org).pdf\n",
      "Uploaded: oreilly-technical-guide-understanding-etl.pdf\n",
      "Uploaded: Mastering Kubernetes 3rd Edition.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import snowflake.connector\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# Snowflake connection configuration\n",
    "SNOWFLAKE_CONFIG = {\n",
    "    \"user\": \"ssalvi\",\n",
    "    \"password\": \"Suyash!1998\",\n",
    "    \"account\": \"jzsqwus-ywb74626\",\n",
    "    # \"warehouse\": \"YOUR_WAREHOUSE\",\n",
    "    \"database\": \"LEARNING_ASSISTANT\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "# Path to your PDFs folder\n",
    "PDF_FOLDER = \"../content/pdfs/\"\n",
    "\n",
    "# Connect to Snowflake\n",
    "def connect_to_snowflake():\n",
    "    return snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "\n",
    "# Extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        return extract_text(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Load PDF data into Snowflake\n",
    "def load_pdfs_to_snowflake():\n",
    "    conn = connect_to_snowflake()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        files = os.listdir(PDF_FOLDER)\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(PDF_FOLDER, file)\n",
    "                content = extract_text_from_pdf(file_path)\n",
    "                \n",
    "                # Insert into Snowflake\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO educational_content (id, title, content)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                \"\"\", (file, file.replace(\".pdf\", \"\"), content))\n",
    "                print(f\"Uploaded: {file}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_pdfs_to_snowflake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Redis Microservices.pdf\n",
      "Processed: Analytics Stack Guidebook.pdf\n",
      "Processed: Node.js Design Patterns 3rd Edition.pdf\n",
      "Processed: Redis For Dummies Limited Edition.pdf\n",
      "Processed: Caching at Scale with Redis Dec 2021.pdf\n",
      "Processed: Caching for Microservices Brief.pdf\n",
      "Error extracting text from ../content/pdfs/Practical Node.js 2nd Edition.pdf: unpack requires a buffer of 30 bytes\n",
      "Skipping Practical Node.js 2nd Edition.pdf due to extraction error\n",
      "Processed: Designing Data-Intensive Applications.pdf\n",
      "Processed: Hands On JavaScript High Performance.pdf\n",
      "Processed: Microservices Building Scalable Software.pdf\n",
      "Processed: Node.js High Performance.pdf\n",
      "Processed: Mastering Node.js.pdf\n",
      "Processed: Object Oriented Design Course Notes.pdf\n",
      "Processed: System Design Interview An Insider’s Guide by Alex Xu (z-lib.org).pdf\n",
      "Processed: oreilly-technical-guide-understanding-etl.pdf\n",
      "Processed: Mastering Kubernetes 3rd Edition.pdf\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "import snowflake.connector\n",
    "import json\n",
    "\n",
    "# Snowflake Configuration\n",
    "SNOWFLAKE_CONFIG = {\n",
    "    \"user\": \"ssalvi\",\n",
    "    \"password\": \"Suyash!1998\",\n",
    "    \"account\": \"jzsqwus-ywb74626\",\n",
    "    # \"warehouse\": \"YOUR_WAREHOUSE\",\n",
    "    \"database\": \"LEARNING_ASSISTANT\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "# Initialize embedding model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings[0].numpy()\n",
    "\n",
    "# Extract text and generate embeddings for each PDF\n",
    "PDF_FOLDER = \"../content/pdfs/\"\n",
    "# def process_pdfs():\n",
    "#     conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     files = os.listdir(PDF_FOLDER)\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".pdf\"):\n",
    "#             file_path = os.path.join(PDF_FOLDER, file)\n",
    "#             content = extract_text(file_path)\n",
    "\n",
    "#             # Generate embedding\n",
    "#             embedding = generate_embedding(content)\n",
    "\n",
    "#             # Insert into Snowflake\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 INSERT INTO educational_content (id, title, content, embedding)\n",
    "#                 VALUES (%s, %s, %s, %s)\n",
    "#             \"\"\", (file, file.replace(\".pdf\", \"\"), content, embedding.tolist()))\n",
    "\n",
    "#     cursor.close()\n",
    "#     conn.close()\n",
    "\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        return extract_text(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_pdfs():\n",
    "    conn = snowflake.connector.connect(**SNOWFLAKE_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        files = os.listdir(PDF_FOLDER)\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(PDF_FOLDER, file)\n",
    "                content = extract_text_from_pdf(file_path)\n",
    "                \n",
    "                # Skip if content extraction failed\n",
    "                if content is None:\n",
    "                    print(f\"Skipping {file} due to extraction error\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Generate embedding and convert to compressed binary\n",
    "                    embedding = generate_embedding(content)\n",
    "                    embedding_bytes = base64.b64encode(embedding.tobytes()).decode('utf-8')\n",
    "\n",
    "                    # Insert into Snowflake\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO educational_content (id, title, content, embedding)\n",
    "                        VALUES (%s, %s, %s, %s)\n",
    "                    \"\"\", (file, file.replace(\".pdf\", \"\"), content, embedding_bytes))\n",
    "                    print(f\"Processed: {file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "                    continue\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "process_pdfs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
